{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLTpDVQk0ozE"
      },
      "source": [
        "# Credit Fraud Training (KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ_YHIuBixz9"
      },
      "source": [
        "## KNN classifier on credit fraud dataset\n",
        "Use K-nearest-neighbor method to create a model that is able to detect potential credit card fraud.\n",
        "\n",
        "\n",
        "### Task 1: Mount your drive\n",
        "Mount your google drive on Colab which allows to access the .csv file included."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLFvC76d6R6D",
        "outputId": "d630c43b-8975-4313-8209-8967cf94388b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIe7xYXUi1b6"
      },
      "source": [
        "### Task 2: Load and preprocess datasets\n",
        "In this program we are using a dataset that has the following features:  \n",
        "\n",
        "V1 | V1 | ... | V10 | Amount | Class\n",
        "---|---|---|---|---|---\n",
        "(float)|(float)|(float)|(float)|(float)|(str)\n",
        "\n",
        "The first ten features are the top PCA values for certain transaction information. The reason only PCA values are given is to protect private information.\n",
        "The **Amount** feature is the amount of money in that particular transaction and the **Class** feature contains two classes **safe** and **Fraud**.\n",
        "Each class has 400 examples, aim to predict the **Class** feature from all the other features, i.e. determine which transactions are fraudulent or not.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sKIMALaKaWh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3172cac6-8990-4ea5-9db3-418dc5030668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train has the shape (640, 11)\n",
            "y_train has the shape (640,)\n",
            "X_test has the shape (160, 11)\n",
            "y_test has the shape (160,)\n",
            "X_train mean is [-4.44089210e-17 -6.93889390e-18  3.33066907e-17  1.66533454e-17\n",
            "  1.94289029e-17  1.66533454e-17 -3.46944695e-17 -1.94289029e-17\n",
            " -4.44089210e-17  0.00000000e+00  7.63278329e-18]\n",
            "X_test mean is [ 0.09347451 -0.09182168  0.15245938 -0.19522097  0.10599188  0.23410519\n",
            "  0.09620048 -0.19714382  0.18255422  0.17135069  0.12558944]\n",
            "Sum of X_train mean is -5.620504062164857e-17\n",
            "Sum of X_test mean is 0.6775393249086965\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "rng = np.random.RandomState(5) # use this if you need to generate a random sample\n",
        "\n",
        "# Load Credit Card Data\n",
        "path = '/content/drive/My Drive/Assignment_3/Assignment-3/creditcard_ece570.csv'\n",
        "data = pd.read_csv(path)\n",
        "# Create X, y data\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "# Split Train, Test Data (80%-20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "# Learn Preprocessing Transform\n",
        "scalar = StandardScaler()\n",
        "labeler = LabelEncoder()\n",
        "scalar.fit(X_train)\n",
        "labeler.fit(y_train)\n",
        "# Apply Transforms\n",
        "X_train = scalar.transform(X_train)\n",
        "X_test = scalar.transform(X_test)\n",
        "y_train = labeler.transform(y_train)\n",
        "y_test = labeler.transform(y_test)\n",
        "\n",
        "# Test Statements\n",
        "print(f'X_train has the shape {X_train.shape}')\n",
        "print(f'y_train has the shape {y_train.shape}')\n",
        "print(f'X_test has the shape {X_test.shape}')\n",
        "print(f'y_test has the shape {y_test.shape}')\n",
        "print(f'X_train mean is {np.mean(X_train, axis=0)}')\n",
        "print(f'X_test mean is {np.mean(X_test, axis=0)}')\n",
        "print(f'Sum of X_train mean is {np.sum(np.mean(X_train, axis=0))}')\n",
        "print(f'Sum of X_test mean is {np.sum(np.mean(X_test, axis=0))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5q1eA_ti67M"
      },
      "source": [
        "### Task 3: Find the optimal KNN estimator\n",
        "We need to find the optimal parameters of the KNN estimator (the model selection problem) using cross validation, and then provide a final estimate of the model's generalization performance via the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DPRzH6CuaXWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8753227-0e77-4804-b798-cd0af6a544be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameters are {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'uniform'}\n",
            "The best accuracy on the training data is 0.953125\n",
            "The best accuracy on the testing data is 0.90625\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "rng = np.random.RandomState(5) # use this if you need to generate a random sample\n",
        "\n",
        "# Set Hyperparameters\n",
        "grid_params = {\n",
        "    'n_neighbors': [1,3,5,7,9,11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'chebyshev'],\n",
        "}\n",
        "# Grid Search\n",
        "KNN_GV = GridSearchCV(KNeighborsClassifier(), grid_params, cv = 5)\n",
        "# Fit Data (training only)\n",
        "KNN_GV = KNN_GV.fit(X_train, y_train)\n",
        "\n",
        "print(f'The best parameters are {KNN_GV.best_params_}')\n",
        "print(f'The best accuracy on the training data is {KNN_GV.score(X_train, y_train)}')\n",
        "print(f'The best accuracy on the testing data is {KNN_GV.score(X_test, y_test)}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}